{'analyzer': 'word', 'tokenizer': 'spacy', 'n_estimators': 300, 'max_depth': 100, 'max_features': 50000, 'ngram_range': '(1, 3)', 'min_df': 2, 'max_df': 0.1}