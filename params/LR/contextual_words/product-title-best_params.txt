{'analyzer': 'word', 'tokenizer': 'spacy', 'max_features': 50000, 'C': 10, 'max_iter': 5000, 'ngram_range': '(1, 1)', 'min_df': 1, 'max_df': 0.3}